{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name:  Gustavo David Quintero Alvarez\n",
      "\n",
      "Honor pledge:  I affirm that I have not given or received any unauthorized help on this assignment, and that this work is my own.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name = \"Gustavo David Quintero Alvarez\"  # write YOUR NAME\n",
    "\n",
    "honorPledge = \"I affirm that I have not given or received any unauthorized \" \\\n",
    "              \"help on this assignment, and that this work is my own.\\n\"\n",
    "\n",
    "\n",
    "print(\"\\nName: \", name)\n",
    "print(\"\\nHonor pledge: \", honorPledge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAC0460 / MAC5832 (2022)\n",
    "<hr>\n",
    "\n",
    "# EP2: Linear regression - analytic solution\n",
    "\n",
    "### Objectives:\n",
    "\n",
    "- to implement and test the analytic solution for the linear regression task (see, for instance, <a href=\"http://work.caltech.edu/slides/slides03.pdf\">Slides of Lecture 03</a> of *Learning from Data*)\n",
    "- to understand the core idea (*optimization of a loss or cost function*) for parameter adjustment in machine learning\n",
    "\n",
    "### What to do:\n",
    "- some cells of this notebook must be filled. Places to be filled are indicated as:\n",
    "<code>\n",
    "    \\# START OF YOUR CODE:\n",
    "    \n",
    "    \\# END OF YOUR CODE\n",
    "</code> \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "Given a dataset $\\{(\\mathbf{x}^{(1)}, y^{(1)}), \\dots ,(\\mathbf{x}^{(N)}, y^{(N)})\\}$ with $\\mathbf{x}^{(i)} \\in \\mathbb{R}^{d}$ and $y^{(i)} \\in \\mathbb{R}$, we would like to approximate the unknown function $f:\\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ (recall that $y^{(i)} =f(\\mathbf{x}^{(i)})$) by means of a linear model $h$:\n",
    "$$\n",
    "h(\\mathbf{x}^{(i)}; \\mathbf{w}, b) = \\mathbf{w}^\\top  \\mathbf{x}^{(i)} + b\n",
    "$$\n",
    "\n",
    "Note that $h(\\mathbf{x}^{(i)}; \\mathbf{w}, b)$ is, in fact, an  [affine transformation](https://en.wikipedia.org/wiki/Affine_transformation) of  $\\mathbf{x}^{(i)}$. As commonly done, we will use the term \"linear\" to refer to an affine transformation.\n",
    "\n",
    "The output of $h$ is a linear transformation of $\\mathbf{x}^{(i)}$. We use the notation $h(\\mathbf{x}^{(i)}; \\mathbf{w}, b)$ to make clear that $h$ is a parametric model, i.e., the transformation $h$ is defined  by the parameters $\\mathbf{w}$ and $b$. We can view vector $\\mathbf{w}$ as a *weight* vector that controls the effect of each *feature* in the prediction.\n",
    "\n",
    "By adding one component with value equal to 1 to the observations $\\mathbf{x}$ (an artificial coordinate), we have:\n",
    "\n",
    "$$\\tilde{\\mathbf{x}} = (1, x_1, \\ldots, x_d) \\in \\mathbb{R}^{1+d}$$\n",
    "\n",
    "and then we can simplify the notation:\n",
    "$$\n",
    "h(\\mathbf{x}^{(i)}; \\mathbf{w}) = \\hat{y}^{(i)} = \\mathbf{w}^\\top  \\tilde{\\mathbf{x}}^{(i)}\n",
    "$$\n",
    "\n",
    "We would like to determine the optimal parameters $\\mathbf{w}$ such that prediction $\\hat{y}^{(i)}$ is as closest as possible to $y^{(i)}$ according to some error metric. Adopting the *mean square error* as such metric we have the following cost function:\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}\\sum_{i=1}^{N}\\big(\\hat{y}^{(i)} - y^{(i)}\\big)^{2}\n",
    "\\end{equation}\n",
    "\n",
    "Thus, the task of determining a function $h$ that is closest to $f$ is reduced to the task of finding the values $\\mathbf{w}$ that minimize $J(\\mathbf{w})$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions\n",
    "The two auxiliary functions below are for generating simulated data and for plotting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An auxiliary function\n",
    "def get_housing_prices_data(N, verbose=True):\n",
    "    \"\"\"\n",
    "    Generates artificial linear data,\n",
    "    where x = square meter, y = house price\n",
    "\n",
    "    :param N: data set size\n",
    "    :type N: int\n",
    "    \n",
    "    :param verbose: param to control print\n",
    "    :type verbose: bool\n",
    "    :return: design matrix, regression targets\n",
    "    :rtype: np.array, np.array\n",
    "    \"\"\"\n",
    "    cond = False\n",
    "    while not cond:\n",
    "        x = np.linspace(90, 1200, N)\n",
    "        gamma = np.random.normal(30, 10, x.size)\n",
    "        y = 50 * x + gamma * 400\n",
    "        x = x.astype(\"float32\")\n",
    "        x = x.reshape((x.shape[0], 1))\n",
    "        y = y.astype(\"float32\")\n",
    "        y = y.reshape((y.shape[0], 1))\n",
    "        cond = min(y) > 0\n",
    "        \n",
    "    xmean, xsdt, xmax, xmin = np.mean(x), np.std(x), np.max(x), np.min(x)\n",
    "    ymean, ysdt, ymax, ymin = np.mean(y), np.std(y), np.max(y), np.min(y)\n",
    "    if verbose:\n",
    "        print(\"\\nX shape = {}\".format(x.shape))\n",
    "        print(\"y shape = {}\\n\".format(y.shape))\n",
    "        print(\"X: mean {}, sdt {:.2f}, max {:.2f}, min {:.2f}\".format(xmean,\n",
    "                                                               xsdt,\n",
    "                                                               xmax,\n",
    "                                                               xmin))\n",
    "        print(\"y: mean {:.2f}, sdt {:.2f}, max {:.2f}, min {:.2f}\".format(ymean,\n",
    "                                                                 ysdt,\n",
    "                                                                 ymax,\n",
    "                                                                 ymin))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another auxiliary function\n",
    "def plot_points_regression(x,\n",
    "                           y,\n",
    "                           title,\n",
    "                           xlabel,\n",
    "                           ylabel,\n",
    "                           prediction=None,\n",
    "                           legend=False,\n",
    "                           r_squared=None,\n",
    "                           position=(90, 100)):\n",
    "    \"\"\"\n",
    "    Plots the data points and the prediction,\n",
    "    if there is one.\n",
    "\n",
    "    :param x: design matrix\n",
    "    :type x: np.array\n",
    "    :param y: regression targets\n",
    "    :type y: np.array\n",
    "    :param title: plot's title\n",
    "    :type title: str\n",
    "    :param xlabel: x axis label\n",
    "    :type xlabel: str\n",
    "    :param ylabel: y axis label\n",
    "    :type ylabel: str\n",
    "    :param prediction: model's prediction\n",
    "    :type prediction: np.array\n",
    "    :param legend: param to control print legends\n",
    "    :type legend: bool\n",
    "    :param r_squared: r^2 value\n",
    "    :type r_squared: float\n",
    "    :param position: text position\n",
    "    :type position: tuple\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    line1, = ax.plot(x, y, 'bo', label='Real data')\n",
    "    if prediction is not None:\n",
    "        line2, = ax.plot(x, prediction, 'r', label='Predicted data')\n",
    "        if legend:\n",
    "            plt.legend(handles=[line1, line2], loc=2)\n",
    "        ax.set_title(title,\n",
    "                 fontsize=20,\n",
    "                 fontweight='bold')\n",
    "    if r_squared is not None:\n",
    "        bbox_props = dict(boxstyle=\"square,pad=0.3\",\n",
    "                          fc=\"white\", ec=\"black\", lw=0.2)\n",
    "        t = ax.text(position[0], position[1], \"$R^2 ={:.4f}$\".format(r_squared),\n",
    "                    size=15, bbox=bbox_props)\n",
    "\n",
    "    ax.set_xlabel(xlabel, fontsize=20)\n",
    "    ax.set_ylabel(ylabel, fontsize=20)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset and the task\n",
    "\n",
    "The first dataset we will use is a toy dataset. We will generate $N=100$ observations with only one *feature* and a real value associated to each of them. We can view these observations as being pairs *(area of a real state in square meters, price of the real state)*. Our task is to construct a model that is able to predict the price of a real state, given its area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X shape = (100, 1)\n",
      "y shape = (100, 1)\n",
      "\n",
      "X: mean 645.0, sdt 323.65, max 1200.00, min 90.00\n",
      "y: mean 44480.91, sdt 16463.12, max 86316.31, min 15054.14\n"
     ]
    }
   ],
   "source": [
    "X, y = get_housing_prices_data(N=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Real estate prices prediction',\n",
    "                       xlabel=\"m\\u00b2\",\n",
    "                       ylabel='$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The solution\n",
    "\n",
    "Given $f:\\mathbb{R}^{N\\times M} \\rightarrow \\mathbb{R}$ and $\\mathbf{A} \\in \\mathbb{R}^{N\\times M}$, we define the gradient of $f$ with respect to $\\mathbf{A}$ as:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\nabla_{\\mathbf{A}}f = \\frac{\\partial f}{\\partial \\mathbf{A}} =  \\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{1,1}} & \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{1,m}} \\\\\n",
    "\\vdots &  \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{n,1}} &  \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{n,m}}\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Let $\\mathbf{X} \\in \\mathbb{R}^{N\\times (1+d)}$ be a matrix (sometimes also called the *design matrix*) whose rows are the extended observations of the dataset and let $\\mathbf{y} \\in \\mathbb{R}^{N}$ be the vector consisting of all values $y^{(i)}$ (i.e., $\\mathbf{X}^{(i,:)} = \\mathbf{\\tilde{x}}^{(i)}$ and $\\mathbf{y}^{(i)} = y^{(i)}$). It can be verified that: \n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})^{T}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})\n",
    "\\end{equation}\n",
    "\n",
    "Using basic matrix derivative concepts we can compute the gradient of $J(\\mathbf{w})$ with respect to $\\mathbf{w}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = \\frac{2}{N} (\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} -\\mathbf{X}^{T}\\mathbf{y})   \n",
    "\\end{equation}\n",
    "\n",
    "Thus, when $\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = 0$ we have \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} = \\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "Hence,\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{w} = (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "Note that this solution has a high computational cost. As the number of variables (*features*) increases, the cost for matrix inversion becomes prohibitive. See  [this text](https://sgfin.github.io/files/notes/CS229_Lecture_Notes.pdf) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy\n",
    "Quoted from [NumPy documentation](https://numpy.org/doc/stable/): \"NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.\"\n",
    "\n",
    "A quick introduction to this library can be found [here](http://cs231n.github.io/python-numpy-tutorial/). Particularly useful for this EP (and this course) are the \"array math\" related tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark>Exercise 1</mark>\n",
    "The objective of this exercise is to apply the solution just described on the dataset above created.\n",
    "\n",
    "Using only **NumPy**, complete the two functions below. Recall that $\\mathbf{X} \\in \\mathbb{R}^{N\\times d}$; thus you will need to add a component of value 1 to each of  the observations in $\\mathbf{X}$ before performing the computation described above.\n",
    "\n",
    "NOTE: Although the dataset above has data of dimension $d=1$, your code must be generic (it should work for $d\\geq1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.1. Weight computation function</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation_weights(X, y):\n",
    "    \"\"\"\n",
    "    Calculates the weights of a linear function using the normal equation method.\n",
    "    You should add into X a new column with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param y: regression targets\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    :return: weight vector\n",
    "    :rtype: np.ndarray(shape=(1+d, 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # START OF YOUR CODE:\n",
    "    \n",
    "    # Defining the dimension of the dataset:\n",
    "    N = X.shape[0]\n",
    "    \n",
    "    # Adding a vector of ones in the first column of X:\n",
    "    X = np.hstack((np.ones((N,1)),X))\n",
    "    \n",
    "    # Defining the matrix A as the product of X^t and X:\n",
    "    A = np.matmul(np.transpose(X),X)\n",
    "    \n",
    "    # Defining the vector as the product of X^t and y:\n",
    "    b = np.matmul(np.transpose(X),y)\n",
    "          \n",
    "    # Returning the solution w = (A^-1)*b:\n",
    "    return np.matmul(np.linalg.inv(A),b)\n",
    "\n",
    "    # END OF YOUR CODE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated w =\n",
      " [[12572.87315316]\n",
      " [   49.46982188]]\n"
     ]
    }
   ],
   "source": [
    "# test of function normal_equation_weights()\n",
    "w = 0  # this is not necessary\n",
    "w = normal_equation_weights(X, y)\n",
    "print(\"Estimated w =\\n\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.2. Prediction function</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation_prediction(X, w):\n",
    "    \"\"\"\n",
    "    Calculates the prediction over a set of observations X using the linear function\n",
    "    characterized by the weight vector w.\n",
    "    You should add into X a new column with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param w: weight vector\n",
    "    :type w: np.ndarray(shape=(1+d, 1))\n",
    "    :param y: regression prediction\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # START OF YOUR CODE:\n",
    "    \n",
    "    # Defining the dimension of the dataset:\n",
    "    N = X.shape[0]\n",
    "    \n",
    "    # Adding a vector of ones in the first column of X:\n",
    "    X = np.hstack((np.ones((N,1)),X))\n",
    "    \n",
    "    # Computing and returning the prediction:\n",
    "    return np.matmul(X,w)\n",
    "\n",
    "    # END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.3. Coefficient of determination</mark>\n",
    "We can use the [$R^2$](https://pt.wikipedia.org/wiki/R%C2%B2) metric (Coefficient of determination) to evaluate how well the linear model fits the data.\n",
    "\n",
    "**Which $ùëÖ^2$ value would you expect to observe ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# test of function normal_equation_prediction()\n",
    "prediction = normal_equation_prediction(X, w)\n",
    "\n",
    "# compute the R2 score using the r2_score function from sklearn\n",
    "# Replace 0 with an appropriate call of the function\n",
    "\n",
    "# START OF YOUR CODE:\n",
    "r_2 = r2_score(y,prediction)\n",
    "# END OF YOUR CODE\n",
    "\n",
    "\n",
    "# plot_points_regression(X,\n",
    "#                        y,\n",
    "#                        title='Real estate prices prediction',\n",
    "#                        xlabel=\"m\\u00b2\",\n",
    "#                        ylabel='$',\n",
    "#                        prediction=prediction,\n",
    "#                        legend=True,\n",
    "#                        r_squared=r_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional tests\n",
    "\n",
    "Let us compute a prediction for $x=650$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area = 650.00  Predicted price = 44728.2574\n"
     ]
    }
   ],
   "source": [
    "# Let us use the prediction function\n",
    "x = np.asarray([650]).reshape(1,1)\n",
    "prediction = normal_equation_prediction(x, w)\n",
    "print(\"Area = %.2f  Predicted price = %.4f\" %(x[0], prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.4. Processing time</mark>\n",
    "\n",
    "Experiment with different number of samples $N$ and observe how processing time varies.\n",
    "\n",
    "Be careful not to use a too large value; it may make jupyter freeze ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X shape = (500, 1)\n",
      "y shape = (500, 1)\n",
      "\n",
      "X: mean 645.0, sdt 321.07, max 1200.00, min 90.00\n",
      "y: mean 44374.94, sdt 16475.40, max 81460.26, min 8776.81\n",
      "\n",
      "Execution time = 0.00000000(s)\n",
      "\n",
      "\n",
      "X shape = (1000, 1)\n",
      "y shape = (1000, 1)\n",
      "\n",
      "X: mean 645.0, sdt 320.75, max 1200.00, min 90.00\n",
      "y: mean 44249.32, sdt 16629.16, max 80949.25, min 6106.54\n",
      "\n",
      "Execution time = 0.00000000(s)\n",
      "\n",
      "\n",
      "X shape = (2000, 1)\n",
      "y shape = (2000, 1)\n",
      "\n",
      "X: mean 645.0, sdt 320.59, max 1200.00, min 90.00\n",
      "y: mean 44318.14, sdt 16562.32, max 82096.43, min 9627.55\n",
      "\n",
      "Execution time = 0.00000000(s)\n",
      "\n",
      "\n",
      "X shape = (4000, 1)\n",
      "y shape = (4000, 1)\n",
      "\n",
      "X: mean 645.0, sdt 320.51, max 1200.00, min 90.00\n",
      "y: mean 44300.99, sdt 16516.43, max 79635.36, min 8406.66\n",
      "\n",
      "Execution time = 0.00100136(s)\n",
      "\n",
      "\n",
      "X shape = (8000, 1)\n",
      "y shape = (8000, 1)\n",
      "\n",
      "X: mean 645.0, sdt 320.47, max 1200.00, min 90.00\n",
      "y: mean 44228.26, sdt 16545.62, max 82279.34, min 4625.66\n",
      "\n",
      "Execution time = 0.00099421(s)\n",
      "\n",
      "\n",
      "X shape = (16000, 1)\n",
      "y shape = (16000, 1)\n",
      "\n",
      "X: mean 645.0, sdt 320.45, max 1200.00, min 90.00\n",
      "y: mean 44178.45, sdt 16507.10, max 81041.49, min 4723.25\n",
      "\n",
      "Execution time = 0.00097728(s)\n",
      "\n",
      "\n",
      "X shape = (32000, 1)\n",
      "y shape = (32000, 1)\n",
      "\n",
      "X: mean 645.0, sdt 320.44, max 1200.00, min 90.00\n",
      "y: mean 44249.55, sdt 16510.23, max 83977.66, min 3213.03\n",
      "\n",
      "Execution time = 0.00093818(s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add other values for N\n",
    "# START OF YOUR CODE:\n",
    "N = [500,1000,2000,4000,8000,16000,32000] \n",
    "# END OF YOUR CODE\n",
    "\n",
    "for i in N:\n",
    "    X, y = get_housing_prices_data(N=i)\n",
    "    init = time.time()\n",
    "    w = normal_equation_weights(X, y)\n",
    "    prediction = normal_equation_prediction(X,w)\n",
    "    init = time.time() - init\n",
    "    \n",
    "    print(\"\\nExecution time = {:.8f}(s)\\n\".format(init))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark>Exercise 2</mark>\n",
    "\n",
    "In this exercise, the goal is to play with the data we have collected in our first class. Download the data file from [here](https://edisciplinas.usp.br/draftfile.php/5062945/user/draft/622707057/dataMAC0460_5832.csv) (or directly from e-disciplinas, se√ß√£o Tarefas). \n",
    "We will also try to explore cases where $d>1$.\n",
    "\n",
    "Note that there might be some invalid data entries. It is up to you how you will handle those data. Note that if you decide to do some pre-processing of the dataset, it should be done in this notebook (you are not allowed to edit the CSV datasheet). Feel free to added new cells if that helps to better organize your code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Shoe number</th>\n",
       "      <th>Trouser number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>53</td>\n",
       "      <td>154</td>\n",
       "      <td>59</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>170</td>\n",
       "      <td>56</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>167</td>\n",
       "      <td>63</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>178</td>\n",
       "      <td>78</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>153</td>\n",
       "      <td>58</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Age  Height  Weight  Shoe number Trouser number\n",
       "0  Female   53     154      59           36             40\n",
       "1    Male   23     170      56           40             38\n",
       "2  Female   23     167      63           37             40\n",
       "3    Male   21     178      78           40             40\n",
       "4  Female   25     153      58           36             38"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# load the dataset\n",
    "df = pd.read_csv('dataMAC0460_5832.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Shoe number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.133663</td>\n",
       "      <td>171.084158</td>\n",
       "      <td>72.004950</td>\n",
       "      <td>39.777228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.934604</td>\n",
       "      <td>12.808496</td>\n",
       "      <td>17.093392</td>\n",
       "      <td>2.857281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>166.250000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>172.500000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.750000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>81.750000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age      Height      Weight  Shoe number\n",
       "count  202.000000  202.000000  202.000000   202.000000\n",
       "mean    28.133663  171.084158   72.004950    39.777228\n",
       "std     11.934604   12.808496   17.093392     2.857281\n",
       "min      3.000000   65.000000   15.000000    24.000000\n",
       "25%     21.000000  166.250000   61.000000    38.000000\n",
       "50%     23.000000  172.500000   70.000000    40.000000\n",
       "75%     29.750000  178.000000   81.750000    42.000000\n",
       "max     67.000000  194.000000  159.000000    46.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's establish 'Weight' as the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      59\n",
       "1      56\n",
       "2      63\n",
       "3      78\n",
       "4      58\n",
       "       ..\n",
       "197    57\n",
       "198    68\n",
       "199    65\n",
       "200    51\n",
       "201    62\n",
       "Name: Weight, Length: 202, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our target variable is the Weight\n",
    "yaux = df['Weight']\n",
    "yaux\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.1. One feature ($d=1$)</mark>\n",
    "\n",
    "We will use 'Height' as the input feature and predict the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = ['Height']\n",
    "X = df.loc[:, feature_cols]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code for computing the following\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute the $R^2$ value\n",
    "- plot the regression graph (use appropriate values for the parameters of function <tt>plot_points_regression()</tt>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yaux' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# START OF YOUR CODE:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Computing the regression weights using X and y:\u001b[39;00m\n\u001b[0;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m202\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m----> 5\u001b[0m y[:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(\u001b[43myaux\u001b[49m)\n\u001b[0;32m      6\u001b[0m w \u001b[38;5;241m=\u001b[39m normal_equation_weights(X, y)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Computing prediction:\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'yaux' is not defined"
     ]
    }
   ],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# Computing the regression weights using X and y:\n",
    "y = np.zeros((202,1))\n",
    "y[:,0] = yaux\n",
    "w = normal_equation_weights(X, y)\n",
    "\n",
    "# Computing prediction:\n",
    "prediction = normal_equation_prediction(X, w)\n",
    "\n",
    "# Computing the R^2 value:\n",
    "r_2 = r2_score(y,prediction)\n",
    "\n",
    "# Ploting the regression graph:\n",
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Weight prediction from height',\n",
    "                       xlabel=\"Weight\",\n",
    "                       ylabel='Height',\n",
    "                       prediction=prediction,\n",
    "                       legend=True,\n",
    "                       r_squared=r_2)\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.2 - Two input features ($d=2$)</mark>\n",
    "\n",
    "Now repeat the exercise using as input the features 'Height' and 'Shoe number'\n",
    "\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute and print the $R^2$ value\n",
    "\n",
    "Note that our plotting function can not be used for this dataset. Here tehre is no need to do the plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - <mark>Three input features ($d=3$)</mark>\n",
    "\n",
    "Now try with three features. There is no need to do plotting here.\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute and print the $R^2$ value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. <mark>Your comments</mark>\n",
    "\n",
    "Write any comments about your implementation or about the results you observed.\n",
    "\n",
    "===>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
