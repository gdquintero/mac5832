{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name:  Gustavo David Quintero Alvarez\n",
      "\n",
      "Honor pledge:  I affirm that I have not given or received any unauthorized help on this assignment, and that this work is my own.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name = \"Gustavo David Quintero Alvarez\"  # write YOUR NAME\n",
    "\n",
    "honorPledge = \"I affirm that I have not given or received any unauthorized \" \\\n",
    "              \"help on this assignment, and that this work is my own.\\n\"\n",
    "\n",
    "\n",
    "print(\"\\nName: \", name)\n",
    "print(\"\\nHonor pledge: \", honorPledge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAC0460 / MAC5832 (2022)\n",
    "<hr>\n",
    "\n",
    "# EP2: Linear regression - analytic solution\n",
    "\n",
    "### Objectives:\n",
    "\n",
    "- to implement and test the analytic solution for the linear regression task (see, for instance, <a href=\"http://work.caltech.edu/slides/slides03.pdf\">Slides of Lecture 03</a> of *Learning from Data*)\n",
    "- to understand the core idea (*optimization of a loss or cost function*) for parameter adjustment in machine learning\n",
    "\n",
    "### What to do:\n",
    "- some cells of this notebook must be filled. Places to be filled are indicated as:\n",
    "<code>\n",
    "    \\# START OF YOUR CODE:\n",
    "    \n",
    "    \\# END OF YOUR CODE\n",
    "</code> \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "Given a dataset $\\{(\\mathbf{x}^{(1)}, y^{(1)}), \\dots ,(\\mathbf{x}^{(N)}, y^{(N)})\\}$ with $\\mathbf{x}^{(i)} \\in \\mathbb{R}^{d}$ and $y^{(i)} \\in \\mathbb{R}$, we would like to approximate the unknown function $f:\\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ (recall that $y^{(i)} =f(\\mathbf{x}^{(i)})$) by means of a linear model $h$:\n",
    "$$\n",
    "h(\\mathbf{x}^{(i)}; \\mathbf{w}, b) = \\mathbf{w}^\\top  \\mathbf{x}^{(i)} + b\n",
    "$$\n",
    "\n",
    "Note that $h(\\mathbf{x}^{(i)}; \\mathbf{w}, b)$ is, in fact, an  [affine transformation](https://en.wikipedia.org/wiki/Affine_transformation) of  $\\mathbf{x}^{(i)}$. As commonly done, we will use the term \"linear\" to refer to an affine transformation.\n",
    "\n",
    "The output of $h$ is a linear transformation of $\\mathbf{x}^{(i)}$. We use the notation $h(\\mathbf{x}^{(i)}; \\mathbf{w}, b)$ to make clear that $h$ is a parametric model, i.e., the transformation $h$ is defined  by the parameters $\\mathbf{w}$ and $b$. We can view vector $\\mathbf{w}$ as a *weight* vector that controls the effect of each *feature* in the prediction.\n",
    "\n",
    "By adding one component with value equal to 1 to the observations $\\mathbf{x}$ (an artificial coordinate), we have:\n",
    "\n",
    "$$\\tilde{\\mathbf{x}} = (1, x_1, \\ldots, x_d) \\in \\mathbb{R}^{1+d}$$\n",
    "\n",
    "and then we can simplify the notation:\n",
    "$$\n",
    "h(\\mathbf{x}^{(i)}; \\mathbf{w}) = \\hat{y}^{(i)} = \\mathbf{w}^\\top  \\tilde{\\mathbf{x}}^{(i)}\n",
    "$$\n",
    "\n",
    "We would like to determine the optimal parameters $\\mathbf{w}$ such that prediction $\\hat{y}^{(i)}$ is as closest as possible to $y^{(i)}$ according to some error metric. Adopting the *mean square error* as such metric we have the following cost function:\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}\\sum_{i=1}^{N}\\big(\\hat{y}^{(i)} - y^{(i)}\\big)^{2}\n",
    "\\end{equation}\n",
    "\n",
    "Thus, the task of determining a function $h$ that is closest to $f$ is reduced to the task of finding the values $\\mathbf{w}$ that minimize $J(\\mathbf{w})$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary functions\n",
    "The two auxiliary functions below are for generating simulated data and for plotting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An auxiliary function\n",
    "def get_housing_prices_data(N, verbose=True):\n",
    "    \"\"\"\n",
    "    Generates artificial linear data,\n",
    "    where x = square meter, y = house price\n",
    "\n",
    "    :param N: data set size\n",
    "    :type N: int\n",
    "    \n",
    "    :param verbose: param to control print\n",
    "    :type verbose: bool\n",
    "    :return: design matrix, regression targets\n",
    "    :rtype: np.array, np.array\n",
    "    \"\"\"\n",
    "    cond = False\n",
    "    while not cond:\n",
    "        x = np.linspace(90, 1200, N)\n",
    "        gamma = np.random.normal(30, 10, x.size)\n",
    "        y = 50 * x + gamma * 400\n",
    "        x = x.astype(\"float32\")\n",
    "        x = x.reshape((x.shape[0], 1))\n",
    "        y = y.astype(\"float32\")\n",
    "        y = y.reshape((y.shape[0], 1))\n",
    "        cond = min(y) > 0\n",
    "        \n",
    "    xmean, xsdt, xmax, xmin = np.mean(x), np.std(x), np.max(x), np.min(x)\n",
    "    ymean, ysdt, ymax, ymin = np.mean(y), np.std(y), np.max(y), np.min(y)\n",
    "    if verbose:\n",
    "        print(\"\\nX shape = {}\".format(x.shape))\n",
    "        print(\"y shape = {}\\n\".format(y.shape))\n",
    "        print(\"X: mean {}, sdt {:.2f}, max {:.2f}, min {:.2f}\".format(xmean,\n",
    "                                                               xsdt,\n",
    "                                                               xmax,\n",
    "                                                               xmin))\n",
    "        print(\"y: mean {:.2f}, sdt {:.2f}, max {:.2f}, min {:.2f}\".format(ymean,\n",
    "                                                                 ysdt,\n",
    "                                                                 ymax,\n",
    "                                                                 ymin))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another auxiliary function\n",
    "def plot_points_regression(x,\n",
    "                           y,\n",
    "                           title,\n",
    "                           xlabel,\n",
    "                           ylabel,\n",
    "                           prediction=None,\n",
    "                           legend=False,\n",
    "                           r_squared=None,\n",
    "                           position=(90, 100)):\n",
    "    \"\"\"\n",
    "    Plots the data points and the prediction,\n",
    "    if there is one.\n",
    "\n",
    "    :param x: design matrix\n",
    "    :type x: np.array\n",
    "    :param y: regression targets\n",
    "    :type y: np.array\n",
    "    :param title: plot's title\n",
    "    :type title: str\n",
    "    :param xlabel: x axis label\n",
    "    :type xlabel: str\n",
    "    :param ylabel: y axis label\n",
    "    :type ylabel: str\n",
    "    :param prediction: model's prediction\n",
    "    :type prediction: np.array\n",
    "    :param legend: param to control print legends\n",
    "    :type legend: bool\n",
    "    :param r_squared: r^2 value\n",
    "    :type r_squared: float\n",
    "    :param position: text position\n",
    "    :type position: tuple\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "    line1, = ax.plot(x, y, 'bo', label='Real data')\n",
    "    if prediction is not None:\n",
    "        line2, = ax.plot(x, prediction, 'r', label='Predicted data')\n",
    "        if legend:\n",
    "            plt.legend(handles=[line1, line2], loc=2)\n",
    "        ax.set_title(title,\n",
    "                 fontsize=20,\n",
    "                 fontweight='bold')\n",
    "    if r_squared is not None:\n",
    "        bbox_props = dict(boxstyle=\"square,pad=0.3\",\n",
    "                          fc=\"white\", ec=\"black\", lw=0.2)\n",
    "        t = ax.text(position[0], position[1], \"$R^2 ={:.4f}$\".format(r_squared),\n",
    "                    size=15, bbox=bbox_props)\n",
    "\n",
    "    ax.set_xlabel(xlabel, fontsize=20)\n",
    "    ax.set_ylabel(ylabel, fontsize=20)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset and the task\n",
    "\n",
    "The first dataset we will use is a toy dataset. We will generate $N=100$ observations with only one *feature* and a real value associated to each of them. We can view these observations as being pairs *(area of a real state in square meters, price of the real state)*. Our task is to construct a model that is able to predict the price of a real state, given its area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X shape = (100, 1)\n",
      "y shape = (100, 1)\n",
      "\n",
      "X: mean 645.0, sdt 323.65, max 1200.00, min 90.00\n",
      "y: mean 44462.21, sdt 17274.28, max 78913.62, min 10880.78\n"
     ]
    }
   ],
   "source": [
    "X, y = get_housing_prices_data(N=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Real estate prices prediction',\n",
    "                       xlabel=\"m\\u00b2\",\n",
    "                       ylabel='$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The solution\n",
    "\n",
    "Given $f:\\mathbb{R}^{N\\times M} \\rightarrow \\mathbb{R}$ and $\\mathbf{A} \\in \\mathbb{R}^{N\\times M}$, we define the gradient of $f$ with respect to $\\mathbf{A}$ as:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\nabla_{\\mathbf{A}}f = \\frac{\\partial f}{\\partial \\mathbf{A}} =  \\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{1,1}} & \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{1,m}} \\\\\n",
    "\\vdots &  \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{n,1}} &  \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{n,m}}\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Let $\\mathbf{X} \\in \\mathbb{R}^{N\\times (1+d)}$ be a matrix (sometimes also called the *design matrix*) whose rows are the extended observations of the dataset and let $\\mathbf{y} \\in \\mathbb{R}^{N}$ be the vector consisting of all values $y^{(i)}$ (i.e., $\\mathbf{X}^{(i,:)} = \\mathbf{\\tilde{x}}^{(i)}$ and $\\mathbf{y}^{(i)} = y^{(i)}$). It can be verified that: \n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})^{T}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})\n",
    "\\end{equation}\n",
    "\n",
    "Using basic matrix derivative concepts we can compute the gradient of $J(\\mathbf{w})$ with respect to $\\mathbf{w}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = \\frac{2}{N} (\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} -\\mathbf{X}^{T}\\mathbf{y})   \n",
    "\\end{equation}\n",
    "\n",
    "Thus, when $\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = 0$ we have \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} = \\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "Hence,\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{w} = (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "Note that this solution has a high computational cost. As the number of variables (*features*) increases, the cost for matrix inversion becomes prohibitive. See  [this text](https://sgfin.github.io/files/notes/CS229_Lecture_Notes.pdf) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy\n",
    "Quoted from [NumPy documentation](https://numpy.org/doc/stable/): \"NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.\"\n",
    "\n",
    "A quick introduction to this library can be found [here](http://cs231n.github.io/python-numpy-tutorial/). Particularly useful for this EP (and this course) are the \"array math\" related tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark>Exercise 1</mark>\n",
    "The objective of this exercise is to apply the solution just described on the dataset above created.\n",
    "\n",
    "Using only **NumPy**, complete the two functions below. Recall that $\\mathbf{X} \\in \\mathbb{R}^{N\\times d}$; thus you will need to add a component of value 1 to each of  the observations in $\\mathbf{X}$ before performing the computation described above.\n",
    "\n",
    "NOTE: Although the dataset above has data of dimension $d=1$, your code must be generic (it should work for $d\\geq1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.1. Weight computation function</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation_weights(X, y):\n",
    "    \"\"\"\n",
    "    Calculates the weights of a linear function using the normal equation method.\n",
    "    You should add into X a new column with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param y: regression targets\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    :return: weight vector\n",
    "    :rtype: np.ndarray(shape=(1+d, 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # START OF YOUR CODE:\n",
    "    \n",
    "    # Defining the dimension of the dataset:\n",
    "    N = X.shape[0]\n",
    "    \n",
    "    # Adding a vector of ones in the first column of X:\n",
    "    X = np.hstack((np.ones((N,1)),X))\n",
    "    \n",
    "    # Defining the matrix A as the product of X^t and X:\n",
    "    A = np.matmul(np.transpose(X),X)\n",
    "    \n",
    "    # Defining the vector as the product of X^t and y:\n",
    "    b = np.matmul(np.transpose(X),y)\n",
    "          \n",
    "    # Returning the solution w = (A^-1)*b:\n",
    "    return np.matmul(np.linalg.inv(A),b)\n",
    "\n",
    "    # END OF YOUR CODE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated w =\n",
      " [[11045.09364725]\n",
      " [   51.80949688]]\n"
     ]
    }
   ],
   "source": [
    "# test of function normal_equation_weights()\n",
    "w = 0  # this is not necessary\n",
    "w = normal_equation_weights(X, y)\n",
    "print(\"Estimated w =\\n\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.2. Prediction function</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation_prediction(X, w):\n",
    "    \"\"\"\n",
    "    Calculates the prediction over a set of observations X using the linear function\n",
    "    characterized by the weight vector w.\n",
    "    You should add into X a new column with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param w: weight vector\n",
    "    :type w: np.ndarray(shape=(1+d, 1))\n",
    "    :param y: regression prediction\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # START OF YOUR CODE:\n",
    "    \n",
    "    # Defining the dimension of the dataset:\n",
    "    N = X.shape[0]\n",
    "    \n",
    "    # Adding a vector of ones in the first column of X:\n",
    "    X = np.hstack((np.ones((N,1)),X))\n",
    "    \n",
    "    # Computing and returning the prediction:\n",
    "    return np.matmul(X,w)\n",
    "\n",
    "    # END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.3. Coefficient of determination</mark>\n",
    "We can use the [$R^2$](https://pt.wikipedia.org/wiki/R%C2%B2) metric (Coefficient of determination) to evaluate how well the linear model fits the data.\n",
    "\n",
    "**Which $ùëÖ^2$ value would you expect to observe ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# test of function normal_equation_prediction()\n",
    "prediction = normal_equation_prediction(X, w)\n",
    "\n",
    "# compute the R2 score using the r2_score function from sklearn\n",
    "# Replace 0 with an appropriate call of the function\n",
    "\n",
    "# START OF YOUR CODE:\n",
    "r_2 = r2_score(y,prediction)\n",
    "# END OF YOUR CODE\n",
    "\n",
    "\n",
    "# plot_points_regression(X,\n",
    "#                        y,\n",
    "#                        title='Real estate prices prediction',\n",
    "#                        xlabel=\"m\\u00b2\",\n",
    "#                        ylabel='$',\n",
    "#                        prediction=prediction,\n",
    "#                        legend=True,\n",
    "#                        r_squared=r_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional tests\n",
    "\n",
    "Let us compute a prediction for $x=650$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area = 650.00  Predicted price = 44721.2666\n"
     ]
    }
   ],
   "source": [
    "# Let us use the prediction function\n",
    "x = np.asarray([650]).reshape(1,1)\n",
    "prediction = normal_equation_prediction(x, w)\n",
    "print(\"Area = %.2f  Predicted price = %.4f\" %(x[0], prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>1.4. Processing time</mark>\n",
    "\n",
    "Experiment with different number of samples $N$ and observe how processing time varies.\n",
    "\n",
    "Be careful not to use a too large value; it may make jupyter freeze ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X shape = (500, 1)\n",
      "y shape = (500, 1)\n",
      "\n",
      "X: mean 645.0, sdt 321.07, max 1200.00, min 90.00\n",
      "y: mean 44703.63, sdt 16718.11, max 82259.31, min 11470.38\n",
      "\n",
      "Execution time = 0.00099826(s)\n",
      "\n",
      "\n",
      "X shape = (1000, 1)\n",
      "y shape = (1000, 1)\n",
      "\n",
      "X: mean 645.0, sdt 320.75, max 1200.00, min 90.00\n",
      "y: mean 44155.50, sdt 16604.43, max 83341.68, min 8264.53\n",
      "\n",
      "Execution time = 0.00100017(s)\n",
      "\n",
      "\n",
      "X shape = (2000, 1)\n",
      "y shape = (2000, 1)\n",
      "\n",
      "X: mean 645.0, sdt 320.59, max 1200.00, min 90.00\n",
      "y: mean 44207.12, sdt 16502.67, max 83553.68, min 5877.48\n",
      "\n",
      "Execution time = 0.00000000(s)\n",
      "\n",
      "\n",
      "X shape = (4000, 1)\n",
      "y shape = (4000, 1)\n",
      "\n",
      "X: mean 645.0, sdt 320.51, max 1200.00, min 90.00\n",
      "y: mean 44221.76, sdt 16424.10, max 82288.59, min 4275.07\n",
      "\n",
      "Execution time = 0.00000000(s)\n",
      "\n",
      "\n",
      "X shape = (8000, 1)\n",
      "y shape = (8000, 1)\n",
      "\n",
      "X: mean 645.0, sdt 320.47, max 1200.00, min 90.00\n",
      "y: mean 44245.32, sdt 16536.22, max 80902.83, min 5980.25\n",
      "\n",
      "Execution time = 0.00100350(s)\n",
      "\n",
      "\n",
      "X shape = (16000, 1)\n",
      "y shape = (16000, 1)\n",
      "\n",
      "X: mean 645.0, sdt 320.45, max 1200.00, min 90.00\n",
      "y: mean 44235.21, sdt 16503.74, max 82839.74, min 6012.12\n",
      "\n",
      "Execution time = 0.00100112(s)\n",
      "\n",
      "\n",
      "X shape = (32000, 1)\n",
      "y shape = (32000, 1)\n",
      "\n",
      "X: mean 645.0, sdt 320.44, max 1200.00, min 90.00\n",
      "y: mean 44212.31, sdt 16516.87, max 85737.41, min 3544.97\n",
      "\n",
      "Execution time = 0.00200319(s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add other values for N\n",
    "# START OF YOUR CODE:\n",
    "N = [500,1000,2000,4000,8000,16000,32000] \n",
    "# END OF YOUR CODE\n",
    "\n",
    "for i in N:\n",
    "    X, y = get_housing_prices_data(N=i)\n",
    "    init = time.time()\n",
    "    w = normal_equation_weights(X, y)\n",
    "    prediction = normal_equation_prediction(X,w)\n",
    "    init = time.time() - init\n",
    "    \n",
    "    print(\"\\nExecution time = {:.8f}(s)\\n\".format(init))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <mark>Exercise 2</mark>\n",
    "\n",
    "In this exercise, the goal is to play with the data we have collected in our first class. Download the data file from [here](https://edisciplinas.usp.br/draftfile.php/5062945/user/draft/622707057/dataMAC0460_5832.csv) (or directly from e-disciplinas, se√ß√£o Tarefas). \n",
    "We will also try to explore cases where $d>1$.\n",
    "\n",
    "Note that there might be some invalid data entries. It is up to you how you will handle those data. Note that if you decide to do some pre-processing of the dataset, it should be done in this notebook (you are not allowed to edit the CSV datasheet). Feel free to added new cells if that helps to better organize your code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Shoe number</th>\n",
       "      <th>Trouser number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>53</td>\n",
       "      <td>154</td>\n",
       "      <td>59</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>170</td>\n",
       "      <td>56</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>167</td>\n",
       "      <td>63</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>178</td>\n",
       "      <td>78</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>153</td>\n",
       "      <td>58</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Age  Height  Weight  Shoe number Trouser number\n",
       "0  Female   53     154      59           36             40\n",
       "1    Male   23     170      56           40             38\n",
       "2  Female   23     167      63           37             40\n",
       "3    Male   21     178      78           40             40\n",
       "4  Female   25     153      58           36             38"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# load the dataset\n",
    "df = pd.read_csv('dataMAC0460_5832.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Shoe number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.133663</td>\n",
       "      <td>171.084158</td>\n",
       "      <td>72.004950</td>\n",
       "      <td>39.777228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.934604</td>\n",
       "      <td>12.808496</td>\n",
       "      <td>17.093392</td>\n",
       "      <td>2.857281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>166.250000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>172.500000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.750000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>81.750000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age      Height      Weight  Shoe number\n",
       "count  202.000000  202.000000  202.000000   202.000000\n",
       "mean    28.133663  171.084158   72.004950    39.777228\n",
       "std     11.934604   12.808496   17.093392     2.857281\n",
       "min      3.000000   65.000000   15.000000    24.000000\n",
       "25%     21.000000  166.250000   61.000000    38.000000\n",
       "50%     23.000000  172.500000   70.000000    40.000000\n",
       "75%     29.750000  178.000000   81.750000    42.000000\n",
       "max     67.000000  194.000000  159.000000    46.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's establish 'Weight' as the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      59\n",
       "1      56\n",
       "2      63\n",
       "3      78\n",
       "4      58\n",
       "       ..\n",
       "197    57\n",
       "198    68\n",
       "199    65\n",
       "200    51\n",
       "201    62\n",
       "Name: Weight, Length: 202, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our target variable is the Weight\n",
    "y = df['Weight']\n",
    "y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.1. One feature ($d=1$)</mark>\n",
    "\n",
    "We will use 'Height' as the input feature and predict the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(202, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = ['Height']\n",
    "X = df.loc[:, feature_cols]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code for computing the following\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute the $R^2$ value\n",
    "- plot the regression graph (use appropriate values for the parameters of function <tt>plot_points_regression()</tt>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:142\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), None)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m r_2 \u001b[38;5;241m=\u001b[39m r2_score(y,prediction)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Ploting the regression graph:\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mplot_points_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                       \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWeight prediction from height\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mxlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWeight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mylabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHeight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mprediction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mlegend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mr_squared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr_2\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mplot_points_regression\u001b[1;34m(x, y, title, xlabel, ylabel, prediction, legend, r_squared, position)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03mPlots the data points and the prediction,\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03mif there is one.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m:type position: tuple\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     34\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m---> 35\u001b[0m line1, \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReal data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     line2, \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mplot(x, prediction, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1632\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_base.py:487\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    484\u001b[0m         kw[prop_name] \u001b[38;5;241m=\u001b[39m val\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(xy) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 487\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43m_check_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m     y \u001b[38;5;241m=\u001b[39m _check_1d(xy[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1327\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m w:\n\u001b[0;32m   1322\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1324\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mWarning\u001b[39;00m,\n\u001b[0;32m   1325\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSupport for multi-dimensional indexing\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1327\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;66;03m# we have definitely hit a pandas index or series object\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;66;03m# cast to a numpy array.\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(w) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3628\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3623\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m         \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m         \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m         \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3628\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3629\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m   3631\u001b[0m \u001b[38;5;66;03m# GH#42269\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5637\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   5634\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5635\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5636\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5637\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), None)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# Computing the regression weights using X and y:\n",
    "w = normal_equation_weights(X, y)\n",
    "\n",
    "# Computing prediction:\n",
    "prediction = normal_equation_prediction(X, w)\n",
    "\n",
    "# Computing the R^2 value:\n",
    "r_2 = r2_score(y,prediction)\n",
    "\n",
    "# Ploting the regression graph:\n",
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Weight prediction from height',\n",
    "                       xlabel=\"Weight\",\n",
    "                       ylabel='Height',\n",
    "                       prediction=prediction,\n",
    "                       legend=True,\n",
    "                       r_squared=r_2)\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <mark>2.2 - Two input features ($d=2$)</mark>\n",
    "\n",
    "Now repeat the exercise using as input the features 'Height' and 'Shoe number'\n",
    "\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute and print the $R^2$ value\n",
    "\n",
    "Note that our plotting function can not be used for this dataset. Here tehre is no need to do the plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - <mark>Three input features ($d=3$)</mark>\n",
    "\n",
    "Now try with three features. There is no need to do plotting here.\n",
    "- compute the regression weights using $\\mathbf{X}$ and $\\mathbf{y}$\n",
    "- compute the prediction\n",
    "- compute and print the $R^2$ value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START OF YOUR CODE:\n",
    "\n",
    "# END OF YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. <mark>Your comments</mark>\n",
    "\n",
    "Write any comments about your implementation or about the results you observed.\n",
    "\n",
    "===>\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
